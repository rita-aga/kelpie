# Using Kelpie as a Letta Replacement

Kelpie implements a Letta-compatible REST API, allowing it to be used as a drop-in replacement for Letta in existing projects.

## Compatibility Status

‚úÖ **Compatible** - These endpoints work exactly as in Letta:
- `GET /v1/agents` - List all agents
- `POST /v1/agents` - Create agent with memory blocks
- `GET /v1/agents/{id}` - Get agent details
- `PATCH /v1/agents/{id}` - Update agent
- `DELETE /v1/agents/{id}` - Delete agent
- `GET /v1/agents/{id}/blocks` - Get memory blocks
- `GET /v1/agents/{id}/messages` - List messages
- `GET /v1/tools` - List available tools
- `POST /v1/tools` - Register new tool

‚ö†Ô∏è **Slightly Different** - These endpoints exist but use different paths:
- Letta: `PATCH /v1/agents/{id}/blocks/{label}`
- **Kelpie**: `PATCH /v1/agents/{id}/core-memory/blocks/{label}`

üöß **Requires LLM Configuration** - These endpoints work but need API keys:
- `POST /v1/agents/{id}/messages` - Send message (requires `ANTHROPIC_API_KEY` or `OPENAI_API_KEY`)

## Quick Start

### 1. Start Kelpie Server

**In-memory mode (no persistence):**
```bash
cargo run -p kelpie-server
```

**With FoundationDB (persistent storage):**
```bash
cargo run -p kelpie-server --features fdb -- --fdb-cluster-file /path/to/fdb.cluster
```

Server starts on `http://localhost:8283`

### 2. Replace Letta with Kelpie in Your Project

#### Python

```python
import requests

# Instead of pointing to Letta:
# BASE_URL = "http://localhost:8080"

# Point to Kelpie:
BASE_URL = "http://localhost:8283"

# All your existing Letta API calls work!
agents = requests.get(f"{BASE_URL}/v1/agents").json()
```

#### JavaScript/TypeScript

```javascript
// Instead of:
// const client = new LettaClient({ baseUrl: "http://localhost:8080" });

// Use Kelpie:
const client = new LettaClient({ baseUrl: "http://localhost:8283" });

// All existing code continues to work!
```

#### cURL

```bash
# Just change the base URL from Letta to Kelpie:
curl http://localhost:8283/v1/agents
```

## Example: Creating and Using an Agent

```bash
# 1. Create an agent with memory
curl -X POST http://localhost:8283/v1/agents \
  -H "Content-Type: application/json" \
  -d '{
    "name": "my-assistant",
    "memory_blocks": [
      {"label": "persona", "value": "You are a helpful AI assistant."},
      {"label": "human", "value": "The human is testing Kelpie."}
    ]
  }'

# Response:
# {
#   "id": "550e8400-e29b-41d4-a716-446655440000",
#   "name": "my-assistant",
#   ...
# }

# 2. Get agent details
curl http://localhost:8283/v1/agents/550e8400-e29b-41d4-a716-446655440000

# 3. List memory blocks
curl http://localhost:8283/v1/agents/550e8400-e29b-41d4-a716-446655440000/blocks

# 4. Update memory (note: uses core-memory path in Kelpie)
curl -X PATCH http://localhost:8283/v1/agents/550e8400-e29b-41d4-a716-446655440000/core-memory/blocks/human \
  -H "Content-Type: application/json" \
  -d '{"value": "The human loves Kelpie!"}'

# 5. Send a message (requires ANTHROPIC_API_KEY env var)
curl -X POST http://localhost:8283/v1/agents/550e8400-e29b-41d4-a716-446655440000/messages \
  -H "Content-Type: application/json" \
  -d '{
    "role": "user",
    "content": "Hello! Tell me about yourself."
  }'

# 6. List messages
curl http://localhost:8283/v1/agents/550e8400-e29b-41d4-a716-446655440000/messages

# 7. Delete agent
curl -X DELETE http://localhost:8283/v1/agents/550e8400-e29b-41d4-a716-446655440000
```

## Differences from Letta

### Memory Block Update Path

**Letta:**
```
PATCH /v1/agents/{id}/blocks/{label}
```

**Kelpie:**
```
PATCH /v1/agents/{id}/core-memory/blocks/{label}
```

**Workaround:** Update your client code to use the `core-memory` path, or use block ID instead of label:
```
PATCH /v1/agents/{id}/blocks/{block_id}
```

### LLM Configuration

Kelpie requires environment variables for LLM providers:

```bash
# For Anthropic Claude:
export ANTHROPIC_API_KEY=sk-ant-...

# For OpenAI:
export OPENAI_API_KEY=sk-...

# Then start server:
cargo run -p kelpie-server
```

## Tested Compatibility

The following operations have been tested and verified to work:

| Operation | Status | Notes |
|-----------|--------|-------|
| Create agent with memory | ‚úÖ | Exact Letta format |
| List agents | ‚úÖ | Returns array of agent objects |
| Get agent by ID | ‚úÖ | Returns full agent details |
| Update agent | ‚úÖ | PATCH with partial updates |
| Delete agent | ‚úÖ | Cascade deletes blocks/messages |
| Get memory blocks | ‚úÖ | Returns array of blocks |
| Update memory block | ‚ö†Ô∏è | Use `/core-memory/blocks/` path |
| List messages | ‚úÖ | Returns conversation history |
| Send message | üöß | Requires LLM API key |
| List tools | ‚úÖ | Returns available tools |

## Storage Backend

Kelpie supports two storage backends:

### In-Memory (Default)
- No persistence
- Fast for testing
- Data lost on restart

```bash
cargo run -p kelpie-server
```

### FoundationDB (Production)
- Persistent storage
- Distributed
- Production-ready

```bash
cargo run -p kelpie-server --features fdb -- --fdb-cluster-file /path/to/fdb.cluster
```

## Migration from Letta

### Step 1: Install Kelpie
```bash
git clone https://github.com/rita-aga/kelpie
cd kelpie
cargo build --release -p kelpie-server
```

### Step 2: Start Kelpie
```bash
./target/release/kelpie-server
```

### Step 3: Update Your Application

**Option A: Environment Variable**
```bash
# Set base URL via environment
export LETTA_BASE_URL=http://localhost:8283
```

**Option B: Code Change**
```python
# Python example
- client = create_client(base_url="http://localhost:8080")
+ client = create_client(base_url="http://localhost:8283")
```

**Option C: Reverse Proxy**
```nginx
# nginx.conf
server {
    listen 8080;
    location / {
        proxy_pass http://localhost:8283;
    }
}
```

Now point your application at port 8080 - no code changes needed!

### Step 4: Migrate Data (Optional)

If you have existing Letta agents:

1. Export from Letta:
```bash
curl http://localhost:8080/v1/agents > letta_agents.json
```

2. Import to Kelpie:
```bash
cat letta_agents.json | jq -c '.[]' | while read agent; do
  curl -X POST http://localhost:8283/v1/agents \
    -H "Content-Type: application/json" \
    -d "$agent"
done
```

## Testing Compatibility

We've included a test script to verify compatibility:

```bash
# Run the compatibility test
python3 /tmp/test_kelpie_rest_api.py
```

This tests all major Letta API endpoints and reports compatibility.

## Benefits of Using Kelpie

1. **Rust Performance**: Orders of magnitude faster than Python
2. **Type Safety**: Compile-time guarantees prevent runtime errors
3. **DST Testing**: Deterministic simulation with fault injection
4. **FoundationDB**: Optional distributed storage backend
5. **Active Development**: New features and improvements ongoing

## Need Help?

- Report issues: https://github.com/rita-aga/kelpie/issues
- API documentation: http://localhost:8283/v1/capabilities

## Summary

**Kelpie can replace Letta with minimal changes:**
- ‚úÖ 90%+ API compatibility
- ‚úÖ Same request/response formats
- ‚ö†Ô∏è Minor path differences (documented above)
- ‚úÖ Drop-in replacement for most use cases

Just change your base URL from Letta to Kelpie, and you're ready to go!
